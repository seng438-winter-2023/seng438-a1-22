>   **SENG 438 - Software Testing, Reliability, and Quality**

**Lab. Report \#1 – Introduction to Testing and Defect Tracking**

| Group: 22      |
|-----------------|
| Topan Budiman |   
| Mark Ngu               |   
| Jacob Schon                |   
| Mouhammed Shah                  |   

[1 Introduction](#Introduction)

[2 High-level description of the exploratory testing plan](#High-level-description-of-the-exploratory-testing-plan)

[3 Comparison of exploratory and manual functional testing](#Comparison-of-exploratory-and-manual-functional-testing)

[4 Notes and discussion of the peer reviews of defect reports](#Notes-and-discussion-of-the-peer-reviews-of-defect-reports)

[5 How the pair testing was managed and team work/effort was
divided](#How-the-pair-testing-was-managed-and-team-workeffort-was-divided)

[6 Difficulties encountered, challenges overcome, and lessons
learned](#Difficulties-encountered-challenges-overcome-and-lessons-learned)

[7 Comments/feedback on the lab and lab document itself](#Commentsfeedback-on-the-lab-and-lab-document-itself)

# Introduction

The lab that we completed was designed to familiarize ourselves with software testing. This 
included beginning to work with System under test (SUT) and defect tracking systems. Additionally, 
we were required to learn more in-depth about and use testing methods such as 
Exploratory (manual non-scripted), and Manual scripted testing, and then finally work with
regression testing, where we retested the system after we added changes.

Initially, our group members had different understandings of what these two testing methods 
would entail, and after a small discussion we were able to get an understanding of where we were 
before beginning the lab. Our initial understanding of exploratory testing was that test cases 
wouldn’t be created beforehand but while following the requirements you would check the 
system and create the tests on the “fly”. For manual scripted testing we believed that it was simply 
where no automation was involved and that the programmer themselves would contribute to 
writing the tests and then creating the scripts.


# High-level description of the exploratory testing plan 

In order to carry out our plan of exploratory testing, we need to know the requirements of the system we are testing. To do so, we will thoroughly go over the requirements from the client to ensure the application is up to par. To perform our testing, we will test all the required functionalities to ensure the system behaves properly. We will also test most functions extensively and check as many paths as possible to ensure edge cases are caught as well.

# Comparison of exploratory and manual functional testing

In exploratory testing, the tests are created by exploring the functionalities of the software while simultaneously executing the tests. Exploratory testing is an unscripted testing strategy, whereas manual functional testing is a scripted testing method. In manual functional testing the tests are designed and recorded first and may be executed later in the testing process. Exploratory testing is more time consuming because every function will need to be tested without any direction but with manual testing you will also miss the same bugs everytime because the script does not change.

Some things we noticed were:
- During the exploratory phase, it is possible to find edge cases that wouldn’t normally be tested in the manual testing phase
- Manual scripted testing is much more useful when testing the basic functionalities of the system because they test intended user inputs
- Exploratory is somewhat inefficient because it is hard to test various functions of a system that you are unfamiliar with compared to manual where the - - scripted test tells you exactly what you need to test
- Manual scripted tests are very efficient to test due to the detailed instructions in the tests, however some manual tests may have inadvertently already - been tested during the exploratory phase
- Both are equally effective at testing different aspects (edge cases for exploratory and basic functionality for manual scripted testing)

# Notes and discussion of the peer reviews of defect reports

Having peer reviews during defect reports was very helpful. This provided reassurance when a bug was found since it was the equivalent to having someone look over your work. This also ensured that the description of each bug was detailed since one person could focus on testing the system and the other would write the description of the bug.

# How the pair testing was managed and team work/effort was divided 

Since we had a group of 4, we divided into two pairs for the pair testing. This allowed us to find more bugs during the exploratory stage both pairs were working concurrently. Since there were 40 test cases in the test suite, we were able to evenly distribute the load between the two pairs since each pair could do 20 test cases each. Overall, we were able to split the work evenly.

# Difficulties encountered, challenges overcome, and lessons learned

- Fully understanding the functionality of the application was difficult and took some time
- While testing during the exploratory phase we had two teams of two group members so we had to make sure to not add duplicate bugs into the backlog
- Although splitting into pairs required lots of coordination, we were able to work more efficiently
- Using a proper bug defect reporter such as Jira eased the process of reporting and keeping track of all bugs found in the system

# Comments/feedback on the lab and lab document itself

- The structure of the assignment doc was very well organized
- It would have been simpler if the final report wasn’t in a markdown file since it was difficult coordinating adding content to one file
- The description for some sections was kind of vague and made it difficult to understand what to do
